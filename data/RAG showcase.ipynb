{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f988db5-bafa-48ad-88e5-b937839fd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "#pip install --upgrade pymupdf\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "from botocore.config import Config\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Langchain core and community components\n",
    "from langchain.embeddings import BedrockEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "# Uncomment if needed\n",
    "# import dbconnection\n",
    "# import psycopg2\n",
    "# from psycopg2 import OperationalError\n",
    "aws_client = boto3.client(service_name=\"bedrock-runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb2cff0-00a8-4caa-83e6-de99843956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you may need to run this in a terminal window if you ge\n",
    "# python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a03d85-cae6-4073-82c1-7a9e77d66c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49606418-7688-457a-9781-332d83333621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF and extract text\n",
    "def read_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590a91ca-8cfb-4011-abc9-62c520d2f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking function with overlap\n",
    "def fixed_size_chunking(text, chunk_size=100, overlap_size=20):\n",
    "    tokens = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap_size):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99949103-3032-40e6-88f5-13d8705d6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list where each item is the text from one page\n",
    "def read_pdf_by_page_cleaned(file_path, min_length=50):\n",
    "    doc = fitz.open(file_path)\n",
    "    pages = []\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text().strip()\n",
    "        if len(text) >= min_length:\n",
    "            pages.append(text)\n",
    "        else:\n",
    "            print(f\"Skipping page {i+1}: too short\")\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8009651-5b7b-4cb1-a589-46582b5b27b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping page 8: too short\n",
      "Skipping page 10: too short\n",
      "Skipping page 12: too short\n",
      "Skipping page 14: too short\n",
      "Skipping page 16: too short\n",
      "Skipping page 18: too short\n",
      "Skipping page 20: too short\n",
      "Skipping page 22: too short\n",
      "Skipping page 24: too short\n",
      "Skipping page 26: too short\n",
      "Skipping page 28: too short\n",
      "Skipping page 30: too short\n",
      "Skipping page 32: too short\n",
      "Skipping page 34: too short\n",
      "Skipping page 36: too short\n",
      "Skipping page 38: too short\n",
      "Skipping page 40: too short\n",
      "Skipping page 42: too short\n",
      "Skipping page 44: too short\n",
      "Skipping page 46: too short\n",
      "Skipping page 48: too short\n",
      "Skipping page 50: too short\n",
      "Skipping page 52: too short\n",
      "Skipping page 54: too short\n",
      "Skipping page 56: too short\n",
      "Skipping page 58: too short\n",
      "Skipping page 60: too short\n",
      "Skipping page 62: too short\n",
      "Skipping page 64: too short\n",
      "Skipping page 66: too short\n",
      "Skipping page 68: too short\n",
      "Skipping page 70: too short\n",
      "Skipping page 72: too short\n",
      "Skipping page 74: too short\n",
      "Skipping page 76: too short\n",
      "Skipping page 78: too short\n",
      "Skipping page 80: too short\n",
      "Skipping page 82: too short\n",
      "Skipping page 84: too short\n",
      "Skipping page 86: too short\n",
      "Skipping page 88: too short\n",
      "Skipping page 90: too short\n",
      "Skipping page 92: too short\n",
      "Skipping page 94: too short\n",
      "Skipping page 96: too short\n",
      "Skipping page 98: too short\n",
      "Skipping page 100: too short\n",
      "Skipping page 102: too short\n",
      "Skipping page 104: too short\n",
      "Skipping page 106: too short\n",
      "Skipping page 108: too short\n",
      "Skipping page 110: too short\n",
      "Skipping page 112: too short\n",
      "Skipping page 114: too short\n",
      "Skipping page 116: too short\n",
      "Skipping page 118: too short\n",
      "Skipping page 120: too short\n",
      "Skipping page 122: too short\n",
      "Skipping page 124: too short\n",
      "Skipping page 126: too short\n",
      "Skipping page 128: too short\n",
      "Skipping page 130: too short\n",
      "Skipping page 132: too short\n",
      "Skipping page 135: too short\n",
      "Skipping page 136: too short\n",
      "Skipping page 138: too short\n",
      "Skipping page 140: too short\n"
     ]
    }
   ],
   "source": [
    "# Use the function\n",
    "file_path = \"./3-Embeddings/data_test/PRIZM.pdf\"\n",
    "\n",
    "cleaned_pages = read_pdf_by_page_cleaned(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08803e9d-372e-4c0a-aa62-24785312cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test chunking\n",
    "#print(f\"Total cleaned pages: {len(cleaned_pages)}\")\n",
    "#print(f\"\\n--- First Clean Page ---\\n{cleaned_pages[40]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fec605d-52a6-48d3-91d7-30c220ba5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"page\": list(range(1, len(cleaned_pages)+1)),\n",
    "    \"text\": cleaned_pages\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25771158-7b6a-4ead-b469-cac64426928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove first 6 rows (b/c they are not prizm segments)\n",
    "df = df.iloc[6:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c4bf94-d407-400d-8d97-288a6e608eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_prizm_segment(text):\n",
    "    match = re.search(r'\\b\\d{2}\\s[–-]\\s.+', text)\n",
    "    return match.group(0).strip() if match else None\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df[\"prizm_segment\"] = df[\"text\"].apply(extract_prizm_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1a8d40-d826-4b1c-be68-31208d66a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a401b2ce-f76b-44d6-ba28-cdfa0007aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_string_size(x, max_chars=2048):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(x, str):\n",
    "        return x[:max_chars]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44e27b9-f858-44d9-b5f0-e54335eb9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value):\n",
    "    value_str = str(value)\n",
    "    cleaned_value = ''.join(char for char in value_str if char.isalnum() or char.isspace())\n",
    "    return cleaned_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f27007-5efe-4c5b-86a3-5837fb1832ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_values(list_stuff: list, num_items: int) -> None:\n",
    "    i=0\n",
    "    for item in list_stuff:\n",
    "        i=i+1\n",
    "        if i>num_items:\n",
    "            return None\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4448df-2c2a-43b7-89d2-e0cb098cad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_documents_with_cohere(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # promote single string to list\n",
    "        single = True\n",
    "    else:\n",
    "        single = False\n",
    "\n",
    "    input_type = \"clustering\"\n",
    "    truncate = \"NONE\"\n",
    "    model_id = \"cohere.embed-english-v3\"\n",
    "    json_params = {\n",
    "        'texts': [limit_string_size(t) for t in texts],\n",
    "        'truncate': truncate,\n",
    "        'input_type': input_type\n",
    "    }\n",
    "    result = aws_client.invoke_model(\n",
    "        body=json.dumps(json_params),\n",
    "        modelId=model_id\n",
    "    )\n",
    "    response = json.loads(result['body'].read().decode())\n",
    "    embeddings = [np.array(vec) for vec in response['embeddings']]\n",
    "    return embeddings[0] if single else embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ba106f-0191-4f5e-b18d-cfa4f9d09e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a dense vector using Amazon Titan with LangChain\n",
    "def generate_titan_vector_embedding(text):\n",
    "    #create an Amazon Titan Text Embeddings client\n",
    "    embeddings_client = BedrockEmbeddings(region_name=\"us-west-2\") \n",
    "\n",
    "    #Invoke the model\n",
    "    embedding = embeddings_client.embed_query(text)\n",
    "    return(np.array(embedding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915cdf99-3d1d-4cb8-8612-0284d0fa825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcdd0dff-2a80-4028-8601-283b1883a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a dense vector using Amazon Titan without using a np.array as a return value\n",
    "def generate_vector_embedding(text):\n",
    "    #create an Amazon Titan Text Embeddings client\n",
    "    embeddings_client = BedrockEmbeddings(region_name=\"us-west-2\") \n",
    "\n",
    "    #Invoke the model\n",
    "    embedding = embeddings_client.embed_query(text)\n",
    "    #Note pgvector does not want a np.array as out manual method\n",
    "    return(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54f2e953-0fb2-412a-84d8-9c422f7a1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.copy()\n",
    "dft[\"embedding\"] = embed_documents_with_cohere(dft[\"text\"].tolist())\n",
    "\n",
    "#export dft as pickle\n",
    "dft.to_pickle('./3-Embeddings/data_test/PRIZM_Embedded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97c3b3dd-557c-4bf5-929d-a2afa6b17ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      7\n",
      "text                                                                                                                                                                                                                                                                                                                                                HOUSEHOLD DEMOGRAPHICS\\n7\\n     \\n     \\n  \\n02 – Networked Neighbors\\nPRIZM® Premier\\nSuburban\\nSOCIAL GROUP\\nS1 – Elite Suburbs\\nLIFESTAGE GROUP\\nF1 – Accumulated Wealth\\nFamily Life\\nU.S. \\nHHs\\n0.98%\\n• Family portrait of suburban wealth\\n• Lifestyle characterized by married couples \\nwith children, high technology use, and \\nsix-ﬁgure incomes earned by business \\nprofessionals\\n• Owns a Mercedes-Benz\\n• Eats at Chipotle\\n• Shops at Crate & Barrel\\n• Enjoys skiing and snowboarding\\nABOUT ME\\nGraduate Plus\\nEMPLOYMENT\\nEDUCATION LEVEL\\nLowest\\nHighest\\nAverage\\nAbove Avg\\nBelow Avg\\nTECH USAGE\\nManagement/Professiona\\nl\\nINCOME PRODUCING ASSETS\\nMedian Household Income: \\n$ 274,135\\n85% Married\\n63% With Kids\\n79% Suburban\\n93% Homeowners \\nHOUSEHOLD AGE\\nSources: Claritas Household Demographics 2022, Claritas Consumer Proﬁles 2022, Claritas GfK US MRI Behavior Proﬁles 2022, Nielsen Online Behavior Proﬁles 2021, Nielsen Television Behavior Proﬁles 2021.\\nCopyright ©2023 Claritas, LLC. Conﬁdential and proprietary.\n",
      "prizm_segment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      02 – Networked Neighbors\n",
      "embedding        [0.0020828247, 0.024658203, -0.058929443, 0.001745224, 0.002784729, -0.036071777, -0.01461792, -0.008369446, -0.047790527, 0.016693115, 0.0016307831, 0.024536133, -0.049102783, -0.036621094, 0.03894043, -0.030166626, 0.03930664, 0.03213501, 0.05432129, -0.005897522, -0.01751709, 0.025421143, -0.03375244, -0.029083252, -7.6293945e-06, 0.0184021, 0.0055656433, 0.001964569, -0.0025730133, -0.002216339, 0.0044403076, 0.023849487, 0.024917603, -0.021636963, 0.016586304, 0.050964355, -0.024154663, -0.008842468, 0.0074157715, 0.0053596497, -0.04626465, 0.048858643, -0.01626587, 0.031188965, -0.079589844, -0.03741455, -0.030166626, 0.011734009, 0.066467285, -0.04144287, 0.00046730042, -0.029418945, 0.020935059, -0.022750854, -0.05114746, -0.0033607483, -0.0064048767, 0.022766113, 0.024291992, -0.038879395, -0.044769287, 0.008682251, 0.034973145, 6.866455e-05, -0.0028457642, -0.04626465, -0.0052490234, 0.02281189, -0.027160645, -0.021499634, 0.031021118, -0.01461792, 0.032196045, -0.036254883, 0.036987305, 0.046447754, -0.026275635, 0.05102539, 0.044128418, -0.04650879, 0.0072364807, -0.02217102, -0.029251099, -0.0026073456, 0.019622803, 0.04147339, 0.0044937134, -0.045928955, 0.015029907, -0.04324341, -0.0034065247, -0.055023193, -0.009643555, 0.064453125, -0.021209717, -0.032073975, 0.016845703, 0.06878662, -0.040649414, -0.046905518, ...]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show full content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(dft.iloc[0])  # first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8c1514-6364-4190-9372-1394cecaccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5598127-277b-43ec-ba24-78460871be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup a query that a user might ask\n",
    "query = \"What Segment makes the most money?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c01085a1-0652-4085-abdc-78f65db2de77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few PRIZM Segments that may match your interest:\n",
      "Abtract: '06 – Winners Circle' with a cosine match of: 0.3801812401302732\n",
      "Abtract: '14 – Kids & Cul-de-Sacs' with a cosine match of: 0.3705638313140499\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "query_vector = embed_documents_with_cohere(query)\n",
    "\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in dft.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedding']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few PRIZM Segments that may match your interest:\")\n",
    "for item in results:\n",
    "    article_title = df.iloc[item[0]]['prizm_segment']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01736160-23c6-4ef0-8a8a-993bc3681b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
